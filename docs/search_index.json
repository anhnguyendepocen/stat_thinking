[
["index.html", "Statistical Reasoning through Computation and R Preface", " Statistical Reasoning through Computation and R Brandon LeBeau and Andrew S. Zieffler 2019-10-08 Preface This book provides a modern statistical reasoning and introduction to statistics text. Computation, using the R programming language, are used instead of relying on traditional statistical theory. "],
["introduction.html", "Chapter 1 Introduction 1.1 Statistics vs Data Science 1.2 Experiments vs Observations 1.3 Data Structure", " Chapter 1 Introduction Here is an intro. And more. 1.1 Statistics vs Data Science 1.2 Experiments vs Observations 1.3 Data Structure "],
["visualization.html", "Chapter 2 Visualization 2.1 Exploring Attributes 2.2 Plot Customization 2.3 Density plots", " Chapter 2 Visualization Data scientists and statisticians visualize data to explore and understand data. Visualization can help analysts identify features in the data such as typical or extreme observations and also for describe variation. Because it is so powerful, data visualiztion is often the first step in any statistical analysis. 2.0.1 College Scorecard Data The U.S. Department of Education publishes data on institutions of higher education in their College Scorecard (https://collegescorecard.ed.gov/) to facilitate transparency and provide information for interested stakeholders (e.g., parents, students, educators). A subset of this data is provided in the file College-scorecard-clean.csv. To illustrate some of the common methods statisticians use to visualize data, we will examine admissions rates for 2,019 institutions of higher education. Before we begin the analysis, we will load two packages, the tidyverse package and the ggformula package. These packages include many useful functions that we will use in this chapter. library(tidyverse) library(ggformula) There are many functions in R to import data. We will use the function read_csv() since the data file we are importing (College-scorecard-clean.csv) is a comma separated value (CSV) file..1 CSV files are a common format for storing data. Since they are encoded as text files they geerally do not take up a lot of space nor computer memory. They get their name from the fact that in the text file, each variable (i.e. column in the data) is separated by a comma within each row. The syntax to import the college scorecard data is as follows: colleges &lt;- read_csv( file = &quot;https://raw.githubusercontent.com/lebebr01/statthink/master/data-raw/College-scorecard-clean.csv&quot;, guess_max = 10000 ) In this syntax we have passed two arguments to the read_csv() function. The first argument, file=, indicates the path to the data file. The data file here is stored on GitHub, so the path is specified as a URL. The second argument, guess_max=, helps ensure that the data are read in appropriately. This argument will be described in more detail later. The syntax to the left of the read_csv() function, namely colleges &lt;-, takes the output of the function and stores it, or in the language of R, assigns it to an object named colleges. In data analysis, it is often useful to use results in later computations, so rather than continually re-running syntax to obtain these results, we can instead store those results in an object and then compute on the object. Here for example, we would like to use the data that was read by the read_csv() function to explore it. When we want to assign computational results to an object, we use the assignment operator, &lt;- . (Note that the assignment operator looks like a left-pointing arrow; it is taking the computational result produced on the right side and storing it in the object to the left side.) 2.0.2 View the Data Once we have imported and assigned the data to an object, it is quite useful to ensure that it was read in appropriately. The head() function will give us a quick snapshot of the data by printing the first six rows of data. head(colleges) ## # A tibble: 6 x 17 ## instnm city stabbr preddeg region locale adm_rate actcmmid ugds ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alaba… Norm… AL Bachel… South… City:… 0.903 18 4824 ## 2 Unive… Birm… AL Bachel… South… City:… 0.918 25 12866 ## 3 Unive… Hunt… AL Bachel… South… City:… 0.812 28 6917 ## 4 Alaba… Mont… AL Bachel… South… City:… 0.979 18 4189 ## 5 The U… Tusc… AL Bachel… South… City:… 0.533 28 32387 ## 6 Aubur… Mont… AL Bachel… South… City:… 0.825 22 4211 ## # … with 8 more variables: costt4_a &lt;dbl&gt;, costt4_p &lt;dbl&gt;, ## # tuitionfee_in &lt;dbl&gt;, tuitionfee_out &lt;dbl&gt;, debt_mdn &lt;dbl&gt;, ## # grad_debt_mdn &lt;dbl&gt;, female &lt;dbl&gt;, bachelor_degree &lt;dbl&gt; 2.1 Exploring Attributes Data scientists and statisticians often start analyses by exploring attributes (i.e., variables) that are of interest to them. For example, suppose we are interested in exploring the admission rates of the institutions in the college scorecard data to determine how selective the different institutions are. We will begin our exploration of admission rates by examining different visualizations of the admissions rate attribute. There is not one perfect visulaiztion for exploring the data. Each visualization has pros and cons; it may highlight some features of the attribute and mask others. It is often necessary to look at many different visualizations of the data in the exploratory phase. 2.1.1 Histograms The first viualization we will examine is a histogram. We can create a histogram of the admission rates using the gf_histrogram() function. (This function is part of the ggformula package which needs to be loaded prior to using the gf_histogram() function.) This function requires two arguments. The first argument is a formula that identifies the variables to be plotted and the second argument, data=, specifies the data object we assigned earlier. The syntax used to create a histrogram of the admission rates is: gf_histogram(~ adm_rate, data = colleges) The formula we provide in the first argument is based on the following general structure: ~ attribute name where the attribute name identified to the right of the ~ is the exact name of one of the columns in the colleges data object. 2.1.2 Interpretting Histograms Histograms are created by collapsing the data into bins and then counting the number of observations that fall into each bin. To show this more clearly in the figure created previously, we can color the bin lines to highlight the different bins. To do this we include an additional argument, color=, in the gf_histogram() function. We can also set the color for the bins themselves using the fill= argument. Here we color the bin lines black and set the bin color to yellow.2 gf_histogram(~ adm_rate, data = colleges, color = &#39;black&#39;, fill = &#39;yellow&#39;) Rather than focusing on any one bin, we typically want to describe the distribution as a whole. For example, it appears as though most institutions admit a high proportion of applicants since the bins to the right of 0.5 have higher counts than the bins that are below 0.5. There are, however, some institutions that are quite selective, only admitting fewer than 25% of the students who apply. 2.1.2.1 Adjusting Number of Bins Interpretation of the distribution is sometimes influenced by the width or number of bins. It is often useful to change the number of bins to explore the impact this may have on your interpretation. This can be accomplished by either (1) changing the width of the bins via thebinwidth= argument in the gf_histogram() function, or (2) changing the number of bins using the bins= argument. Below we show both methods: gf_histogram(~ adm_rate, data = colleges, color = &#39;black&#39;, fill = &#39;yellow&#39;, bins = 10) gf_histogram(~ adm_rate, data = colleges, color = &#39;black&#39;, fill = &#39;yellow&#39;, binwidth = .01) In general, our interpretation remains the same, namely that most institutions admit a high proportion of applicants. When we used a bin width of 0.01, however, we were able to see that several institutions admit 100% of applicants. This was obscured in the other histograms we examined. As a data scientist these institutions might warrant a more nuanced examination. 2.2 Plot Customization There are many ways to further customize the plot we produced to make it more appealing. For example, you might want to change the label on the x-axis from adm_rate to something more informative. Or, you may want to add a descriptive title to your plot. These customizations can be specified using the gf_labs() function. 2.2.1 Axes labels To change the labels on the x- and y-axes, we can use the arguments x= and y= in the gf_labs() function. These arguments take the text for the label you want to add to each axis, respectively. Here we change the text on the x-axis to “Admission Rate” and the text on the y-axis to “Frequency”. The gf_labs() function is connected to the histogram by linking the gf_histogram() and gf_labs() functions with the pipe operator (%&gt;%). gf_histogram(~ adm_rate, data = colleges, color = &#39;black&#39;, fill = &#39;yellow&#39;, bins = 25) %&gt;% gf_labs( x = &#39;Admission Rate&#39;, y = &#39;Frequency&#39; ) 2.2.2 Plot title and subtitle We can also add a title and subtitle to our plot. Similar to changing the axis labels, these are added using gf_labs(), but using the title= and subtitle= arguments. gf_histogram(~ adm_rate, data = colleges, color = &#39;black&#39;, fill = &#39;yellow&#39;, bins = 25) %&gt;% gf_labs( x = &#39;Admission Rate&#39;, y = &#39;Frequency&#39;, title = &#39;Distribution of admission rates for 2,019 institutions of higher education.&#39;, subtitle = &#39;Data Source: U.S. Department of Education College Scorecard&#39; ) 2.2.3 Plot theme By default, the plot has a grey background and white grid lines. This can be modified to using the gf_theme() function. For example, in the syntax below we change the plot theme to a white background with no grid lines using theme_classic(). Again, the gf_theme() is linked to the histogram with the pipe operator. gf_histogram(~ adm_rate, data = colleges, color = &#39;black&#39;, fill = &#39;yellow&#39;, bins = 25) %&gt;% gf_labs( x = &#39;Admission Rate&#39;, y = &#39;Frequency&#39;, title = &#39;Distribution of admission rates for 2,019 institutions of higher education.&#39;, subtitle = &#39;Data Source: U.S. Department of Education College Scorecard&#39; ) %&gt;% gf_theme(theme_classic()) We have created a custom theme to use in the gf_theme() function that we will use for most of the plots in the book. The theme, theme_statthinking() is included in the statthink library, a supplemental package to the text that can be installed and loaded with the following commands: remotes::install_github(&#39;lebebr01/statthink&#39;) ## Skipping install of &#39;statthink&#39; from a github remote, the SHA1 (03b24970) has not changed since last install. ## Use `force = TRUE` to force installation library(statthink) ## ## Attaching package: &#39;statthink&#39; ## The following object is masked _by_ &#39;.GlobalEnv&#39;: ## ## colleges We can then change the theme in a similar manner to how we changed the theme before. gf_histogram(~ adm_rate, data = colleges, color = &#39;black&#39;, bins = 25) %&gt;% gf_labs( x = &#39;Admission Rate&#39;, y = &#39;Frequency&#39;, title = &#39;Distribution of admission rates for 2,000 institutions of higher education.&#39;, subtitle = &#39;Data Source: U.S. Department of Education College Scorecard&#39; ) %&gt;% gf_theme(theme_statthinking()) 2.2.3.1 Setting the default plot theme Since we will be using this theme for all of our plots, it is useful to make it the default theme (rather than the grey bckground with white gridlines). To set a different theme as the default, we will use the theme_set() function and call our theme_statthinking() within this function. theme_set(theme_statthinking()) Now when we create a plot, it will automatically use the statthinking theme without having to specify this in the gf_theme() function. gf_histogram(~ adm_rate, data = colleges, color = &#39;black&#39;, bins = 25) %&gt;% gf_labs( x = &#39;Admission Rate&#39;, y = &#39;Frequency&#39;, title = &#39;Distribution of admission rates for 2,000 institutions of higher education.&#39;, subtitle = &#39;Data Source: U.S. Department of Education College Scorecard&#39; ) 2.3 Density plots Another plot that is useful for exploring attributes is the density plot. This plot usually highlights similar distributional features as the histogram, but the visualization does not have the same dependency on the specification of bins. Density plots can be created with the gf_density() function which takes similar arguments as gf_histogram(), namely a formula identifying the attribute to be plotted and the data object.3 gf_density(~ adm_rate, data = colleges) Our interpretation remains that most institutions admit a high proportion of applicants. In fact, colleges that admit around 75% of their applicants have the highest probability density. The axis labels, title, subtitle can be customized with gf_labs() in the same manner as with the histogram. The color= and fill= arguments in gf_density() will color the density curve and area under the density curve, respectively. gf_density(~ adm_rate, data = colleges, color = &#39;black&#39;, fill = &#39;yellow&#39;) %&gt;% gf_labs( x = &#39;Admission Rate&#39;, y = &#39;Probability density&#39;, title = &#39;Distribution of admission rates for 2,019 institutions of higher education.&#39;, subtitle = &#39;Data Source: U.S. Department of Education College Scorecard&#39; ) This function is a part of the tidyverse package, so you need to be sure to run library(tidyverse) prior to using read_csv().↩ R knows the names of 657 colors. To see these names type colors() at the command prompt.↩ The default kernel used in gf_density() is the normal kernel.↩ "],
["descriptive-statistics-applying-functions-to-columns-of-data.html", "Chapter 3 Descriptive Statistics / Applying functions to columns of data 3.1 Applying Functions to Data 3.2 Setup 3.3 Functions to columns of data 3.4 Considering Groups 3.5 Other statistics of center 3.6 Measures of Variation 3.7 Other measures of variation 3.8 Dichtomous Attributes", " Chapter 3 Descriptive Statistics / Applying functions to columns of data 3.1 Applying Functions to Data Data visualization is often the first step on the statistical journey to explore a research question. However, this is usually not where the journey stops, instead additional analyses are often performed to learn more about the average trends seen in the data. These can often be split into two broad categories, Descriptive Statistics Inferential Statistics Descriptive Statistics help to describe the data and are particularly useful to give a single numeric summary for a single variable. We will explore this idea more fully in this section. Inferential Statistics help us to make broader statements from the data we have to the larger group of interest, commonly referred to as the population. More details on these steps later in the course. 3.2 Setup We are going to use some real data about higher education institutions from the college scorecard (https://collegescorecard.ed.gov/) to explore the types of conclusions we can make from the data. The college scorecard releases data on higher education institutions to help make the institutions more transparent and provide a place for parents, students, educators, etc can get information about specific instituations from a third party (i.e. US Department of Education). 3.2.1 Loading R packages library(tidyverse) ## ── Attaching packages ────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.2.1 ✔ purrr 0.3.2 ## ✔ tibble 2.1.3 ✔ dplyr 0.8.3 ## ✔ tidyr 1.0.0 ✔ stringr 1.4.0 ## ✔ readr 1.3.1 ✔ forcats 0.4.0 ## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(ggformula) ## Loading required package: ggstance ## ## Attaching package: &#39;ggstance&#39; ## The following objects are masked from &#39;package:ggplot2&#39;: ## ## geom_errorbarh, GeomErrorbarh ## ## New to ggformula? Try the tutorials: ## learnr::run_tutorial(&quot;introduction&quot;, package = &quot;ggformula&quot;) ## learnr::run_tutorial(&quot;refining&quot;, package = &quot;ggformula&quot;) library(mosaic) ## Loading required package: lattice ## Loading required package: mosaicData ## Loading required package: Matrix ## ## Attaching package: &#39;Matrix&#39; ## The following objects are masked from &#39;package:tidyr&#39;: ## ## expand, pack, unpack ## Registered S3 method overwritten by &#39;mosaic&#39;: ## method from ## fortify.SpatialPolygonsDataFrame ggplot2 ## ## The &#39;mosaic&#39; package masks several functions from core packages in order to add ## additional features. The original behavior of these functions should not be affected by this. ## ## Note: If you use the Matrix package, be sure to load it BEFORE loading mosaic. ## ## Attaching package: &#39;mosaic&#39; ## The following object is masked from &#39;package:Matrix&#39;: ## ## mean ## The following objects are masked from &#39;package:dplyr&#39;: ## ## count, do, tally ## The following object is masked from &#39;package:purrr&#39;: ## ## cross ## The following object is masked from &#39;package:ggplot2&#39;: ## ## stat ## The following objects are masked from &#39;package:stats&#39;: ## ## binom.test, cor, cor.test, cov, fivenum, IQR, median, ## prop.test, quantile, sd, t.test, var ## The following objects are masked from &#39;package:base&#39;: ## ## max, mean, min, prod, range, sample, sum library(statthink) theme_set(theme_statthinking()) 3.2.2 Read in Data The below code will read in the data for us to use in the future. The R function to read in the data is read_csv(). Function arguments are passed within the parentheses and for the read_csv() function the first argument is the path to the data. The data for this example are posted on GitHub in a comma separated file. This means the data is stored in a text format and each variable (i.e. column in the data) is separated by a comma. This is a common format data is stored. The data is stored to an object named colleges. In R (and other statistical programming languages), it is common to use objects to store results to use later. In this instance, we would like to read in the data and store it to use it later. For example, we will likely want to explore the data visually to see if we can extract some trends from the data. The assignment to an object in R is done with the &lt;- assignment operator. Finally, there is one additional argument, guess_max which helps to ensure that the data are read in appropriately. More on this later. head(colleges) ## # A tibble: 6 x 17 ## instnm city stabbr preddeg region locale adm_rate actcmmid ugds ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alaba… Norm… AL Bachel… South… City:… 0.903 18 4824 ## 2 Unive… Birm… AL Bachel… South… City:… 0.918 25 12866 ## 3 Unive… Hunt… AL Bachel… South… City:… 0.812 28 6917 ## 4 Alaba… Mont… AL Bachel… South… City:… 0.979 18 4189 ## 5 The U… Tusc… AL Bachel… South… City:… 0.533 28 32387 ## 6 Aubur… Mont… AL Bachel… South… City:… 0.825 22 4211 ## # … with 8 more variables: costt4_a &lt;dbl&gt;, costt4_p &lt;dbl&gt;, ## # tuitionfee_in &lt;dbl&gt;, tuitionfee_out &lt;dbl&gt;, debt_mdn &lt;dbl&gt;, ## # grad_debt_mdn &lt;dbl&gt;, female &lt;dbl&gt;, bachelor_degree &lt;dbl&gt; 3.3 Functions to columns of data Data are often stored in a tabular format where the rows of the data are the units and the columns in a data frame are the varaibles. This is shown in the college scorecard data above where the rows of the data are specific institutions of higher education and the columns represent various attributes about those higher education institutions. This is a common structure to store data where each row represents a unique unit or measurement occasion for longitudinal data. In the data visualization units, we accessed columns of data to view the distribution of the particular variable. For example, we explore histograms of admission rate. Instead of visualizing the data, now we will apply functions to these columns to calculate statistics of interest. In particular, the focus will be on the calculating statistics for variables that are numeric rather than representing categories. We will discuss this in more detail as we move along. Let’s keep talking about the admission rate as we have explored that visually already and start with an example. df_stats(~ adm_rate, data = colleges, median) ## median_adm_rate ## 1 0.7077 The df_stats() function takes a formula syntax that is similar to the syntax used for viewing a univariate distribution you saw earlier. In particular, the variable that we wish to compute a statistic on is specified after the ~. The next argument is the data argument. Finally, subsequent arguments after the data argument are functions that we want to compute for the variable specified. Here, I compute the median which happens to be, 0.708. The median is also referred to as the 50% percentile and is the location where half of the data (in this case higher education institutions) are above and below an admission rate of 70.8%. Let’s think where this shows up on the admission rate distribution we plotted earlier. gf_histogram(~ adm_rate, data = colleges, bins = 30) %&gt;% gf_vline(color = &#39;blue&#39;, xintercept = ~df_stats(~ adm_rate, data = colleges, median)[[1]], size = 1) You’ll notice that the line is just to the left of the main peak of the data. Does it appear that half of the data are below and half are above the blue line in the figure? The median is a special percentile, however other percentiles may be of interest. For example, maybe we’d want to know what the 20th percentile is or the 80th percentile to apply to a school that isn’t too selective or is not selective at all. We can compute these with the df_stats() function again. q &lt;- colleges %&gt;% df_stats(~ adm_rate, quantile(c(0.2, 0.5, 0.8)), nice_names = TRUE) q ## X20. X50. X80. ## 1 0.51428 0.7077 0.86932 Let’s look where these fall on our distribution. gf_histogram(~ adm_rate, data = colleges, bins = 30) %&gt;% gf_vline(color = &#39;blue&#39;, xintercept = ~ value, data = gather(q), size = 1) Does it appear that 20% of the data are below the first line and 20% are above the last line? Difficult to view on the histogram. An empirical distribution figure, sometimes called an ogive, can be helpful to show these. gf_ecdf(~ adm_rate, data = colleges) %&gt;% gf_vline(color = &#39;blue&#39;, xintercept = ~ value, data = gather(q), linetype = 2) %&gt;% gf_hline(color = &#39;darkblue&#39;, yintercept = ~c(0.2, 0.5, 0.8), data = NA, linetype = 3) %&gt;% gf_labs(y = &#39;Cumulative proportion&#39;) Here you can see that the horizontal lines cross over the vertical lines at the specified values (i.e. 20% for the first vertical line, 50% for the second vertical line, 80% for the final vertical line). 3.4 Considering Groups We’ve spent a lot of time trying to reason about other variables that may be important in explaining variation in our variable of interest. So far we have only explored the variable without considering other variables, in practice that is not that useful. Instead, it is common to compute conditional statistics based on other characteristics in the data. An example may help to show the idea more clearly. colleges %&gt;% df_stats(adm_rate ~ region, median) ## region median_adm_rate ## 1 US Service Schools 0.10740 ## 2 New England 0.73590 ## 3 Mid East 0.73735 ## 4 Great Lakes 0.71110 ## 5 Plains 0.69600 ## 6 Southeast 0.65965 ## 7 Southwest 0.71220 ## 8 Rocky Mountains 0.82865 ## 9 Far West 0.70360 ## 10 Outlying Areas 0.81160 Presented above are the conditional medians for the higher education institutions in different areas of the country. More specifically, the data are essentially split into subgroups and the median is computed for each of those subgroups instead of pooling all institutions into a single data frame. The formula syntax is now outcome ~ grouping where the variable of interest (i.e. commonly a numeric variable) and the variable to the right of the ~ is the grouping variable. This syntax is similar to the violin plots that were created earlier. Can you see differences in the admission rates across the regions? One thing that is useful to add in when computing conditional statisics, is how many data points are in each group. This is particularly useful when the groups are different sizes, which is common. To do this, we can add another function to the df_stats() function. colleges %&gt;% df_stats(adm_rate ~ region, median, length) ## region median_adm_rate length_adm_rate ## 1 US Service Schools 0.10740 4 ## 2 New England 0.73590 167 ## 3 Mid East 0.73735 458 ## 4 Great Lakes 0.71110 297 ## 5 Plains 0.69600 200 ## 6 Southeast 0.65965 454 ## 7 Southwest 0.71220 133 ## 8 Rocky Mountains 0.82865 50 ## 9 Far West 0.70360 221 ## 10 Outlying Areas 0.81160 35 This adds another columns which represents the number of observations that went into the median calculation for each group. The syntax above also shows that you can add additional functions separated by a comma in the df_stats() function and are not limited to a single function. We will take advantage of this feature later on. 3.4.1 Adding additional groups What if we thought more than one variable was important in explaining variation in the outcome variable? These can also be added to the df_stats() function for additional conditional statistics. The key is to add another variable to the right-hand side of the formula argument. More than one variable are separated with a + symbol. colleges %&gt;% df_stats(adm_rate ~ region + preddeg, median, length) ## region preddeg median_adm_rate length_adm_rate ## 1 New England Certificate Degree 0.81820 15 ## 2 Mid East Certificate Degree 0.79505 64 ## 3 Great Lakes Certificate Degree 0.83960 23 ## 4 Plains Certificate Degree 0.82140 19 ## 5 Southeast Certificate Degree 0.75700 27 ## 6 Southwest Certificate Degree 0.72365 12 ## 7 Rocky Mountains Certificate Degree 0.67200 5 ## 8 Far West Certificate Degree 0.76470 37 ## 9 Outlying Areas Certificate Degree 1.00000 5 ## 10 New England Associate Degree 0.78430 7 ## 11 Mid East Associate Degree 0.80290 54 ## 12 Great Lakes Associate Degree 0.79515 22 ## 13 Plains Associate Degree 0.74610 8 ## 14 Southeast Associate Degree 0.72525 34 ## 15 Southwest Associate Degree 0.42260 5 ## 16 Rocky Mountains Associate Degree 0.83970 5 ## 17 Far West Associate Degree 0.58935 12 ## 18 Outlying Areas Associate Degree 0.87040 6 ## 19 US Service Schools Bachelor Degree 0.10740 4 ## 20 New England Bachelor Degree 0.72980 145 ## 21 Mid East Bachelor Degree 0.70790 340 ## 22 Great Lakes Bachelor Degree 0.70560 252 ## 23 Plains Bachelor Degree 0.68330 173 ## 24 Southeast Bachelor Degree 0.64180 393 ## 25 Southwest Bachelor Degree 0.71975 116 ## 26 Rocky Mountains Bachelor Degree 0.82865 40 ## 27 Far West Bachelor Degree 0.69260 172 ## 28 Outlying Areas Bachelor Degree 0.70905 24 3.5 Other statistics of center So far we have been discussing the median. The median attempts to provide a single number summary for the center of the distribution. It is a robust statistic, but likely isn’t the most popular statistic to provide a location for the center of a distribution. The mean is often more commonly used as a measure of the center of a distribution. Part of this is due to the usage of the mean in common statistical methods and the mean also uses the values of all the data in the calculation. The median only considers the values of the middle score or scores, therefore this statistic is less sensitive to extreme values than the mean. I like to look at both statistics and this can provide some insight into the distribution of interest. We can add the mean using the df_stats() function by adding the function mean. stats_compute &lt;- colleges %&gt;% df_stats(adm_rate ~ region, median, mean, length) stats_compute ## region median_adm_rate mean_adm_rate length_adm_rate ## 1 US Service Schools 0.10740 0.1302000 4 ## 2 New England 0.73590 0.6672838 167 ## 3 Mid East 0.73735 0.6920234 458 ## 4 Great Lakes 0.71110 0.7015263 297 ## 5 Plains 0.69600 0.7000135 200 ## 6 Southeast 0.65965 0.6560097 454 ## 7 Southwest 0.71220 0.6696759 133 ## 8 Rocky Mountains 0.82865 0.7800680 50 ## 9 Far West 0.70360 0.6682570 221 ## 10 Outlying Areas 0.81160 0.7885600 35 Do you notice any trends in the direction the mean and median typically follow? More specifically, is the mean typically larger than the median or vice versa? Let’s visualize them. gf_histogram(~ adm_rate, data = colleges, bins = 30) %&gt;% gf_facet_wrap(~ region) %&gt;% gf_vline(color = &#39;blue&#39;, xintercept = ~ median_adm_rate, data = stats_compute, size = 1) %&gt;% gf_vline(color = &#39;lightblue&#39;, xintercept = ~ mean_adm_rate, data = stats_compute, size = 1) What is different about the distributions that have larger differences in the mean and median? 3.6 Measures of Variation So far we have focused primarily on applying functions to columns of data to provide a single numeric summary for where the center of the distribution may lie. The center of the distribution is important, however the primary goal in research and with statistics is to try to understand the variation in the distribution. One crude measure of variation that is intuitive is the range of a variable. The range is the difference between the smallest and the largest number in the data. We can compute this with the df_stats() function. colleges %&gt;% df_stats(~ adm_rate, range) ## range_adm_rate_1 range_adm_rate_2 ## 1 0 1 The details of the df_stats() function are in the previous course notes. The output for this computation returns two values, the minimum and maximum value in the data and unsurprisingly, is 0 and 1 respectively. The range is most useful as a data checking process to ensure that the variable contains values that are theoretically possible, which is true in this case. The range is known as a biased statistic in that it will almost always be smaller than the population value. Therefore, we would like a better statistic for measures of variation. 3.6.1 Robust measure of variation A robust measure of variation that often is used in tandem with the median is the interquartile range (IQR). This statistic can be calculated in two ways, either using the IQR() or quantile() function. Both are presented below. colleges %&gt;% df_stats(~ adm_rate, IQR, quantile(c(0.25, 0.75)), nice_names = TRUE) ## IQR_adm_rate X25. X75. ## 1 0.28575 0.5524 0.83815 The IQR is the difference between the 75th and 25th percentiles and in this example equals 0.285 or about 28.5%. As the IQR represents differences in percentiles, we could say that the middle 50% of the distribution is found between 55% and 84% and the middle 50% is spread out by about 28.5%. The idea behind the IQR representing differences in percentiles allows us to extend this to different percentiles that may be more directly interpretable for a given situation. For example, suppose we wanted to know how spread out the middle 80% of the distribution is. We can do this directly by computing the 90th and 10th percentiles and finding the difference between the two. mid_80 &lt;- colleges %&gt;% df_stats(~ adm_rate, quantile(c(0.1, 0.9)), nice_names = TRUE) mid_80 ## X10. X90. ## 1 0.39284 0.94706 As you can see, once you extend the amount of the distribution contained, the distance increases, now to 0.555 or 55.5% the the range of the middle 80% of the admission rate distribution. We can also visualize what this looks like. gf_histogram(~ adm_rate, data = colleges, bins = 30, color = &#39;black&#39;) %&gt;% gf_vline(color = &#39;blue&#39;, xintercept = ~ value, data = gather(mid_80), size = 1) We can also view the exact percentages using the empirical cumulative density function. gf_ecdf(~ adm_rate, data = colleges) %&gt;% gf_vline(color = &#39;blue&#39;, xintercept = ~ value, data = gather(mid_80), size = 1) 3.6.2 Variation by Group These statistics can also be calculated by different grouping variables similar to what was done with statisitcs of center. Now the variable of interest is on the left-hand side of the equation and the grouping variable is on the right hand side. iqr_groups &lt;- colleges %&gt;% df_stats(adm_rate ~ region, IQR, quantile(c(0.25, 0.75)), nice_names = TRUE) iqr_groups ## region IQR_adm_rate X25. X75. ## 1 US Service Schools 0.052000 0.09280 0.144800 ## 2 New England 0.288000 0.54525 0.833250 ## 3 Mid East 0.279425 0.57140 0.850825 ## 4 Great Lakes 0.220300 0.60580 0.826100 ## 5 Plains 0.272200 0.56990 0.842100 ## 6 Southeast 0.286950 0.52525 0.812200 ## 7 Southwest 0.311400 0.51900 0.830400 ## 8 Rocky Mountains 0.281950 0.64590 0.927850 ## 9 Far West 0.306700 0.52480 0.831500 ## 10 Outlying Areas 0.318600 0.64135 0.959950 This can also be visualized to see how these statistics vary across the groups. gf_histogram(~ adm_rate, data = colleges, bins = 30, color = &#39;black&#39;) %&gt;% gf_vline(color = &#39;blue&#39;, xintercept = ~ value, data = filter(pivot_longer(iqr_groups, IQR_adm_rate:&#39;X75.&#39;), name %in% c(&#39;X25.&#39;, &#39;X75.&#39;)), size = 1) %&gt;% gf_facet_wrap(~ region) 3.7 Other measures of variation There are many other variation measures that are used in statistics. We will apply a functional approach to these and try to visualize what they are trying to represent. The statistics discussed here represent deviations from the mean, either the average absolute deviation or the average squared deviation. colleges %&gt;% df_stats(~ adm_rate, sd, var) ## sd_adm_rate var_adm_rate ## 1 0.2113571 0.04467182 In order to compute the mean absolute error, we first need to define a new function. mae &lt;- function(x, na.rm = TRUE, ...) { avg &lt;- mean(x, na.rm = na.rm, ...) abs_avg &lt;- abs(x - avg) mean(abs_avg) } We can now use this new function just like any other function. colleges %&gt;% df_stats(~ adm_rate, sd, var, mae) ## sd_adm_rate var_adm_rate mae_adm_rate ## 1 0.2113571 0.04467182 0.1692953 3.8 Dichtomous Attributes Dichotomous attributes are common attributes and these take on two unique values. Sometimes these represent categories, such as “Passed” vs “Not-Passed” or “Have Cancer” vs “Does not have cancer” but other times these attributes may be represented numerically. When represented numerically, using 0’s and 1’s for the numerical representation has some advantages over other schemes, although really any numerical quantity could be used to represent the categories. Part of the advantages we will explore later when fitting statistical models to the data attributes, but another advantage is the ability to generate useful descriptive statistics more easily with dichotomous attributes that are represented with 0’s and 1’s. 3.8.1 Applying functions to dichotomous attributes count(colleges, bachelor_degree) ## # A tibble: 2 x 2 ## bachelor_degree n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 360 ## 2 1 1659 colleges %&gt;% df_stats(~ bachelor_degree, sum, mean, median, sd, IQR, length) ## sum_bachelor_degree mean_bachelor_degree median_bachelor_degree ## 1 1659 0.8216939 1 ## sd_bachelor_degree IQR_bachelor_degree length_bachelor_degree ## 1 0.382865 0 2019 "],
["multivariate-visualization.html", "Chapter 4 Multivariate Visualization 4.1 Facetting", " Chapter 4 Multivariate Visualization library(tidyverse) library(ggformula) library(statthink) # Import data colleges &lt;- read_csv( file = &quot;https://raw.githubusercontent.com/lebebr01/statthink/master/data-raw/College-scorecard-clean.csv&quot;, guess_max = 10000 ) Real world data are never as simple exploring a distribution of a single variable, particularly when trying to understand individual variation. In most cases things interact, move in tandem, and many phenomena help to explain the variable of interest. For example, when thinking about admission rates, what may be some important factors that would explain some of the reasons why higher education institutions differ in their admission rates? Take a few minutes to brainstorm some ideas. gf_histogram(~ adm_rate, data = colleges, bins = 30, fill = ~ preddeg) %&gt;% gf_labs(x = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, fill = &quot;Primary Deg&quot;) Often density plots are easier to visualize when there are more than one group. To plot more than one density curve, we need to specify the color argument instead of fill. gf_density(~ adm_rate, data = colleges, color = ~ preddeg) %&gt;% gf_labs(x = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, color = &quot;Primary Deg&quot;) gf_density(~ adm_rate, data = colleges, fill = ~ preddeg) %&gt;% gf_labs(x = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, fill = &quot;Primary Deg&quot;) gf_density(~ adm_rate, data = colleges, fill = ~ preddeg, color = ~ preddeg) %&gt;% gf_labs(x = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, color = &quot;Primary Deg&quot;, fill = &quot;Primary Deg&quot;) gf_density(~ adm_rate, data = colleges, color = ~ preddeg, fill = &#39;gray85&#39;, size = 1) %&gt;% gf_labs(x = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, color = &quot;Primary Deg&quot;) ## Violin Plots Violin plots are another way to make comparisons of distributions across groups. Violin plots are also easier to show more groups on a single graph. Violin plots are density plots that are mirrored to be fully enclosed. Best to explore with an example.ArithmeticError gf_violin(adm_rate ~ preddeg, data = colleges) %&gt;% gf_labs(y = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, x = &quot;Primary Deg&quot;) Aesthetically, these figures are a bit more pleasing to look at if they include a light fill color. This is done similar to the density plots shown above with the fill = argument.ArithmeticError gf_violin(adm_rate ~ preddeg, data = colleges, fill = &#39;gray85&#39;) %&gt;% gf_labs(y = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, x = &quot;Primary Deg&quot;) Adding quantiles are useful to aid in the comparison with the violin plots. These can be added with the draw_quantiles argument. gf_violin(adm_rate ~ preddeg, data = colleges, fill = &#39;gray85&#39;, draw_quantiles = c(.1, .5, .9)) %&gt;% gf_labs(y = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, x = &quot;Primary Deg&quot;) ### Violin Plots with many groups Many groups are more easily shown in the violin plot framework. With many groups, it is often of interest to put the long x-axis labels representing each group on the y-axis so that it reads the correct direction and the labels do not run into each other. This can be done with the gf_refine() function with coord_flip(). gf_violin(adm_rate ~ region, data = colleges, fill = &#39;gray80&#39;, draw_quantiles = c(.1, .5, .9)) %&gt;% gf_labs(y = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, x = &quot;US Region&quot;) %&gt;% gf_refine(coord_flip()) 4.1 Facetting Facetting is another way to explore distributions of two or more variables. gf_violin(adm_rate ~ region, data = colleges, fill = &#39;gray80&#39;, draw_quantiles = c(.1, .5, .9)) %&gt;% gf_labs(y = &#39;Admission Rate (in %)&#39;, title = &#39;Multivariate distribution of higher education admission rates by degree type&#39;, x = &quot;US Region&quot;) %&gt;% gf_refine(coord_flip()) %&gt;% gf_facet_wrap(~ preddeg) "],
["classification.html", "Chapter 5 Classification 5.1 Topic: Decision Trees", " Chapter 5 Classification In this example, we will explore data from the titanic that comes from Kaggle (https://www.kaggle.com/c/titanic/data). You can view the attributes in the data from the link previous. The following set of code will install a couple a new packages that we will utilize for this section of the course, the titanic package has the data we will use and the rpart package includes functions to perform the tree based models we will employ. 5.1 Topic: Decision Trees library(tidyverse) ## ── Attaching packages ────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.2.1 ✔ purrr 0.3.2 ## ✔ tibble 2.1.3 ✔ dplyr 0.8.3 ## ✔ tidyr 1.0.0 ✔ stringr 1.4.0 ## ✔ readr 1.3.1 ✔ forcats 0.4.0 ## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(ggformula) ## Loading required package: ggstance ## ## Attaching package: &#39;ggstance&#39; ## The following objects are masked from &#39;package:ggplot2&#39;: ## ## geom_errorbarh, GeomErrorbarh ## ## New to ggformula? Try the tutorials: ## learnr::run_tutorial(&quot;introduction&quot;, package = &quot;ggformula&quot;) ## learnr::run_tutorial(&quot;refining&quot;, package = &quot;ggformula&quot;) library(mosaic) ## Loading required package: lattice ## Loading required package: mosaicData ## Loading required package: Matrix ## ## Attaching package: &#39;Matrix&#39; ## The following objects are masked from &#39;package:tidyr&#39;: ## ## expand, pack, unpack ## Registered S3 method overwritten by &#39;mosaic&#39;: ## method from ## fortify.SpatialPolygonsDataFrame ggplot2 ## ## The &#39;mosaic&#39; package masks several functions from core packages in order to add ## additional features. The original behavior of these functions should not be affected by this. ## ## Note: If you use the Matrix package, be sure to load it BEFORE loading mosaic. ## ## Attaching package: &#39;mosaic&#39; ## The following object is masked from &#39;package:Matrix&#39;: ## ## mean ## The following objects are masked from &#39;package:dplyr&#39;: ## ## count, do, tally ## The following object is masked from &#39;package:purrr&#39;: ## ## cross ## The following object is masked from &#39;package:ggplot2&#39;: ## ## stat ## The following objects are masked from &#39;package:stats&#39;: ## ## binom.test, cor, cor.test, cov, fivenum, IQR, median, ## prop.test, quantile, sd, t.test, var ## The following objects are masked from &#39;package:base&#39;: ## ## max, mean, min, prod, range, sample, sum library(titanic) library(rpart) library(rsample) library(rpart.plot) library(statthink) theme_set(theme_statthinking()) titanic &lt;- bind_rows(titanic_train, titanic_test) %&gt;% mutate(survived = ifelse(Survived == 1, &#39;Survived&#39;, &#39;Died&#39;)) %&gt;% select(-Survived) %&gt;% drop_na(survived) head(titanic) ## PassengerId Pclass Name ## 1 1 3 Braund, Mr. Owen Harris ## 2 2 1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) ## 3 3 3 Heikkinen, Miss. Laina ## 4 4 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) ## 5 5 3 Allen, Mr. William Henry ## 6 6 3 Moran, Mr. James ## Sex Age SibSp Parch Ticket Fare Cabin Embarked survived ## 1 male 22 1 0 A/5 21171 7.2500 S Died ## 2 female 38 1 0 PC 17599 71.2833 C85 C Survived ## 3 female 26 0 0 STON/O2. 3101282 7.9250 S Survived ## 4 female 35 1 0 113803 53.1000 C123 S Survived ## 5 male 35 0 0 373450 8.0500 S Died ## 6 male NA 0 0 330877 8.4583 Q Died count(titanic, survived) ## # A tibble: 2 x 2 ## survived n ## &lt;chr&gt; &lt;int&gt; ## 1 Died 549 ## 2 Survived 342 gf_bar(~ survived, data = titanic) 5.1.1 Fitting a Classification Tree Let’s class_tree our first classification tree to predict the dichotomous attribute, survival. For this, we will use the rpart() function from the rpart package. The first argument to the rpart() function is a formula where the outcome of interest is specified to the left of the ~ and the attributes that are predictive of the outcome are specified to the right of the ~ separated with + signs. The second argument specifies the method for which we want to run the analysis, in this case we want to classify individuals based on the values in the data, therefore we specify method = ‘class’. The final argument is the data element, in this case titanic. In this example, I picked a handful of attributes that would seem important. These can either be numeric or represent categories, the method does not care the type of attributes that are included in the analysis. Notice that I save the computation to the object, class_tree. class_tree &lt;- rpart(survived ~ Pclass + Sex + Age + Fare + Embarked + SibSp + Parch, method = &#39;class&#39;, data = titanic) rpart.plot(class_tree, roundint = FALSE, type = 3, branch = .3) rpart.rules(class_tree, cover = TRUE) ## survived cover ## 0.11 when Sex is male &amp; Age &lt; 6.5 &amp; SibSp &gt;= 3 1% ## 0.11 when Sex is female &amp; Pclass &gt;= 3 &amp; Fare &gt;= 23 3% ## 0.17 when Sex is male &amp; Age &gt;= 6.5 62% ## 0.30 when Sex is female &amp; Pclass &gt;= 3 &amp; Fare is 18 to 23 &amp; Embarked is S 1% ## 0.41 when Sex is female &amp; Pclass &gt;= 3 &amp; Fare &lt; 11 &amp; Embarked is S 4% ## 0.70 when Sex is female &amp; Pclass &gt;= 3 &amp; Fare &lt; 23 &amp; Embarked is C or Q 6% ## 0.81 when Sex is female &amp; Pclass &gt;= 3 &amp; Fare is 11 to 18 &amp; Embarked is S 2% ## 0.95 when Sex is female &amp; Pclass &lt; 3 19% ## 1.00 when Sex is male &amp; Age &lt; 6.5 &amp; SibSp &lt; 3 2% 5.1.2 Pruning Trees One downside of decision trees, is that they can tend to overfit the data and capitalize on chance variation in our sample that we can not generalize to another sample. This means that there are features in the current sample that would not be present in another sample of data. There are a few ways to overcome this, one is to prune the tree to only include the attributes that are most important and improve the classification accuracy. One measure of this can be used is called the complexity parameter (CP) and this statistic attempts to balance the tree complexity related to how strongly the levels of the tree improve the classification accuracy. We can view these statistics with the printcp() and plotcp() functions where the only argument to be specified is the classification tree computation that was saved in the previous step. printcp(class_tree) ## ## Classification tree: ## rpart(formula = survived ~ Pclass + Sex + Age + Fare + Embarked + ## SibSp + Parch, data = titanic, method = &quot;class&quot;) ## ## Variables actually used in tree construction: ## [1] Age Embarked Fare Pclass Sex SibSp ## ## Root node error: 342/891 = 0.38384 ## ## n= 891 ## ## CP nsplit rel error xerror xstd ## 1 0.444444 0 1.00000 1.00000 0.042446 ## 2 0.030702 1 0.55556 0.55556 0.035750 ## 3 0.023392 3 0.49415 0.51754 0.034823 ## 4 0.020468 4 0.47076 0.50292 0.034448 ## 5 0.010234 5 0.45029 0.51462 0.034749 ## 6 0.010000 8 0.41813 0.53216 0.035188 plotcp(class_tree) prune_class_tree &lt;- prune(class_tree, cp = .02) rpart.plot(prune_class_tree, roundint = FALSE, type = 3, branch = .3) 5.1.3 Accuracy titanic_predict &lt;- titanic %&gt;% mutate(tree_predict = predict(prune_class_tree, type = &#39;class&#39;)) %&gt;% cbind(predict(prune_class_tree, type = &#39;prob&#39;)) head(titanic_predict, n = 20) ## PassengerId Pclass ## 1 1 3 ## 2 2 1 ## 3 3 3 ## 4 4 1 ## 5 5 3 ## 6 6 3 ## 7 7 1 ## 8 8 3 ## 9 9 3 ## 10 10 2 ## 11 11 3 ## 12 12 1 ## 13 13 3 ## 14 14 3 ## 15 15 3 ## 16 16 2 ## 17 17 3 ## 18 18 2 ## 19 19 3 ## 20 20 3 ## Name Sex Age ## 1 Braund, Mr. Owen Harris male 22 ## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 ## 3 Heikkinen, Miss. Laina female 26 ## 4 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35 ## 5 Allen, Mr. William Henry male 35 ## 6 Moran, Mr. James male NA ## 7 McCarthy, Mr. Timothy J male 54 ## 8 Palsson, Master. Gosta Leonard male 2 ## 9 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) female 27 ## 10 Nasser, Mrs. Nicholas (Adele Achem) female 14 ## 11 Sandstrom, Miss. Marguerite Rut female 4 ## 12 Bonnell, Miss. Elizabeth female 58 ## 13 Saundercock, Mr. William Henry male 20 ## 14 Andersson, Mr. Anders Johan male 39 ## 15 Vestrom, Miss. Hulda Amanda Adolfina female 14 ## 16 Hewlett, Mrs. (Mary D Kingcome) female 55 ## 17 Rice, Master. Eugene male 2 ## 18 Williams, Mr. Charles Eugene male NA ## 19 Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele) female 31 ## 20 Masselmani, Mrs. Fatima female NA ## SibSp Parch Ticket Fare Cabin Embarked survived ## 1 1 0 A/5 21171 7.2500 S Died ## 2 1 0 PC 17599 71.2833 C85 C Survived ## 3 0 0 STON/O2. 3101282 7.9250 S Survived ## 4 1 0 113803 53.1000 C123 S Survived ## 5 0 0 373450 8.0500 S Died ## 6 0 0 330877 8.4583 Q Died ## 7 0 0 17463 51.8625 E46 S Died ## 8 3 1 349909 21.0750 S Died ## 9 0 2 347742 11.1333 S Survived ## 10 1 0 237736 30.0708 C Survived ## 11 1 1 PP 9549 16.7000 G6 S Survived ## 12 0 0 113783 26.5500 C103 S Survived ## 13 0 0 A/5. 2151 8.0500 S Died ## 14 1 5 347082 31.2750 S Died ## 15 0 0 350406 7.8542 S Died ## 16 0 0 248706 16.0000 S Survived ## 17 4 1 382652 29.1250 Q Died ## 18 0 0 244373 13.0000 S Survived ## 19 1 0 345763 18.0000 S Died ## 20 0 0 2649 7.2250 C Survived ## tree_predict Died Survived ## 1 Died 0.83182640 0.1681736 ## 2 Survived 0.05294118 0.9470588 ## 3 Survived 0.41025641 0.5897436 ## 4 Survived 0.05294118 0.9470588 ## 5 Died 0.83182640 0.1681736 ## 6 Died 0.83182640 0.1681736 ## 7 Died 0.83182640 0.1681736 ## 8 Died 0.88888889 0.1111111 ## 9 Survived 0.41025641 0.5897436 ## 10 Survived 0.05294118 0.9470588 ## 11 Survived 0.41025641 0.5897436 ## 12 Survived 0.05294118 0.9470588 ## 13 Died 0.83182640 0.1681736 ## 14 Died 0.83182640 0.1681736 ## 15 Survived 0.41025641 0.5897436 ## 16 Survived 0.05294118 0.9470588 ## 17 Died 0.88888889 0.1111111 ## 18 Died 0.83182640 0.1681736 ## 19 Survived 0.41025641 0.5897436 ## 20 Survived 0.41025641 0.5897436 titanic_predict %&gt;% count(survived, tree_predict) ## # A tibble: 4 x 3 ## survived tree_predict n ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; ## 1 Died Died 492 ## 2 Died Survived 57 ## 3 Survived Died 97 ## 4 Survived Survived 245 gf_bar(~ survived, fill = ~tree_predict, data = titanic_predict) gf_bar(~ survived, fill = ~tree_predict, data = titanic_predict, position = &quot;fill&quot;) %&gt;% gf_labs(y = &#39;Proportion&#39;) %&gt;% gf_refine(scale_y_continuous(breaks = seq(0, 1, .1))) titanic_predict %&gt;% mutate(same_class = ifelse(survived == tree_predict, 1, 0)) %&gt;% df_stats(~ same_class, mean, sum) ## mean_same_class sum_same_class ## 1 0.8271605 737 5.1.4 Comparison to Baseline titanic_predict &lt;- titanic_predict %&gt;% mutate(tree_predict_full = predict(class_tree, type = &#39;class&#39;)) titanic_predict %&gt;% count(survived, tree_predict_full) ## # A tibble: 4 x 3 ## survived tree_predict_full n ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; ## 1 Died Died 521 ## 2 Died Survived 28 ## 3 Survived Died 115 ## 4 Survived Survived 227 gf_bar(~ survived, fill = ~tree_predict_full, data = titanic_predict, position = &quot;fill&quot;) %&gt;% gf_labs(y = &quot;proportion&quot;) %&gt;% gf_refine(scale_y_continuous(breaks = seq(0, 1, .1))) titanic_predict %&gt;% mutate(same_class = ifelse(survived == tree_predict_full, 1, 0)) %&gt;% df_stats(~ same_class, mean, sum) ## mean_same_class sum_same_class ## 1 0.8395062 748 5.1.4.1 Absolute vs Relative Comparison 5.1.5 Training/Test Data So far we have used the entire data to make our classification. This is not best practice and we will explore this is a bit more detail. First, take a minute to hypothesize why using the entire data to make our classification prediction may not be the best? It is common to split the data prior to fitting a classification/prediction model into a training data set in which the model makes a series of predictions on the data, learns which data attributes are the most important, etc. Then, upon successfully identifying a useful model with the training data, test these model predictions on data that the model has not seen before. This is particularly important as the algorithms to make the predictions are very good at understanding and exploiting small differences in the data used to fit the model. Therefore, exploring the extent to which the model does a good job on data the model has not seen is a better test to the utility of the model. We will explore in more detail the impact of not using the training/test data split later, but first, let’s refit the classification tree to the titanic data by splitting the data into 70% training and 30% test data. Why 70% training and 30% test? This is a number that is sometimes used as the splitting, an 80/20 split is also common. The main idea behind the making the test data smaller is so that the model has more data to train on initially to understand the attributes from the data. Secondly, the test data does not need to be quite as large, but we would like it to be representative. Here, the data are not too large, about 1000 passengers with available survival data, therefore, withholding more data helps to ensure the test data is representative of the 1000 total passengers. Splitting the data into training/test This is done with the rsample package utilizing three functions, initial_split(), training(), and test(). The initial_split() function helps to take the initial random sample and the proportion of data to use for the training data is initially identified. The random sample is done without replacement meaning that the data are randomly selected, but can not show up in the data more than once. Then, after using the initial_split() function, the training() and test() functions are used on the resulting output from initial_split() to obtain the training and test data respectively. It is good practice to use the set.seed() function to save the seed that was used as this is a random process. Without using the set.seed() function, the same split of data would likely not be able to be recreated in the code was ran again. Let’s do the data splitting. titanic &lt;- bind_rows(titanic_train, titanic_test) %&gt;% mutate(survived = ifelse(Survived == 1, &#39;Survived&#39;, &#39;Died&#39;)) %&gt;% drop_na(survived) set.seed(2019) titanic_split &lt;- initial_split(titanic, prop = .7) titanic_train &lt;- training(titanic_split) titanic_test &lt;- testing(titanic_split) class_tree &lt;- rpart(survived ~ Pclass + Sex + Age + Fare + Embarked + SibSp + Parch, method = &#39;class&#39;, data = titanic_train) rpart.plot(class_tree, roundint = FALSE, type = 3, branch = .3) prune_class_tree &lt;- prune(class_tree, cp = .02) rpart.plot(prune_class_tree, roundint = FALSE, type = 3, branch = .3) This seems like a reasonable model. Let’s check the model accuracy. titanic_predict &lt;- titanic_train %&gt;% mutate(tree_predict = predict(prune_class_tree, type = &#39;class&#39;)) titanic_predict %&gt;% mutate(same_class = ifelse(survived == tree_predict, 1, 0)) %&gt;% df_stats(~ same_class, mean, sum) ## mean_same_class sum_same_class ## 1 0.8445513 527 This is actually slightly better accuracy compared to the model last time, about xxx compared to about xxx prediction accuracy. But, let’s test the model out on the test data to see the prediction accuracy for the test data, the real test. titanic_predict_test &lt;- titanic_test %&gt;% mutate(tree_predict = predict(prune_class_tree, newdata = titanic_test, type = &#39;class&#39;)) titanic_predict_test %&gt;% mutate(same_class = ifelse(survived == tree_predict, 1, 0)) %&gt;% df_stats(~ same_class, mean, sum) ## mean_same_class sum_same_class ## 1 0.7827715 209 For the test data, prediction accuracy was quite a bit lower, about xxx. 5.1.6 Introduction to resampling/bootstrap To explore these ideas in more detail, it will be helpful to use a statistical technique called resampling or the bootstrap. We will use these ideas a lot going forward in this course. In very simple terminology, resampling or the bootstrap can help us understand uncertainty in our estimates and also allow us to be more flexible in the statistics that we run. The main drawback of resampling and bootstrap methods is that they can be computationally heavy, therefore depending on the situation, more time is needed to come to the conclusion desired. Resampling and bootstrap methods use the sample data we have and perform the sampling procedure again treating the sample we have data for as the population. Generating the new samples is done with replacement (more on this later). This resampling is done many times (100, 500, 1000, etc.) with more in general being better. As an example with the titanic data, let’s take the titanic data, assume this is the population of interest, and resample from this population 1000 times (with replacement) and each time we will calculate the proportion that survived the disaster in each sample. Before we write the code for this, a few questions to consider. Would you expect the proportion that survived to be the same in each new sample? Why or why not? Sampling with replacement keeps coming up, what do you think this means? Hypothesize why sampling with replacement would be a good idea? Let’s now try the resampling with the calculation of the proportion that survived. We will then save these 1000 survival proportions and create a visualization. resample_titanic &lt;- function(...) { titanic %&gt;% sample_n(nrow(titanic), replace = TRUE) %&gt;% df_stats(~ Survived, mean) } survival_prop &lt;- map(1:1000, resample_titanic) %&gt;% bind_rows() gf_density(~ mean_Survived, data = survival_prop) 5.1.6.1 Bootstrap variation in prediction accuracy We can apply these same methods to evaluate the prediction accuracy based on the classification model above. When using the bootstrap, we can get an estimate for how much variation there is in the classification accuracy based on the sample that we have. In addition, we can explore how different the prediction accuracy would be for many samples when using all the data and by splitting the data into training and test sets. Bootstrap full data. Let’s first explore the full data to see how much variation there is in the prediction accuracy using all of the data. Here we will again use the sample_n() function to sample with replacement, then fit the classification model to each of these samples, then calculate the prediction accuracy. First, I’m going to write a function to do all of these steps one time. calc_predict_acc &lt;- function(data) { rsamp_titanic &lt;- titanic %&gt;% sample_n(nrow(titanic), replace = TRUE) class_model &lt;- rpart(survived ~ Pclass + Sex + Age + Fare + SibSp + Parch, method = &#39;class&#39;, data = rsamp_titanic, cp = .02) titanic_predict &lt;- rsamp_titanic %&gt;% mutate(tree_predict = predict(class_model, type = &#39;class&#39;)) titanic_predict %&gt;% mutate(same_class = ifelse(survived == tree_predict, 1, 0)) %&gt;% df_stats(~ same_class, mean, sum) } calc_predict_acc() ## mean_same_class sum_same_class ## 1 0.8451178 753 To do the bootstrap, this process can be replicated many times. In this case, I’m going to do 500. In practice, we would likely want to do a few more. predict_accuracy_fulldata &lt;- map(1:2000, calc_predict_acc) %&gt;% bind_rows() gf_density(~ mean_same_class, data = predict_accuracy_fulldata) calc_predict_acc_split &lt;- function(data) { titanic_split &lt;- initial_split(titanic, prop = .7) titanic_train &lt;- training(titanic_split) titanic_test &lt;- testing(titanic_split) class_model &lt;- rpart(survived ~ Pclass + Sex + Age + Fare + SibSp + Parch, method = &#39;class&#39;, data = titanic_train, cp = .02) titanic_predict &lt;- titanic_test %&gt;% mutate(tree_predict = predict(class_model, newdata = titanic_test, type = &#39;class&#39;)) titanic_predict %&gt;% mutate(same_class = ifelse(survived == tree_predict, 1, 0)) %&gt;% df_stats(~ same_class, mean, sum) } calc_predict_acc_split() ## mean_same_class sum_same_class ## 1 0.8277154 221 predict_accuracy_traintest &lt;- map(1:2000, calc_predict_acc_split) %&gt;% bind_rows() gf_density(~ mean_same_class, data = predict_accuracy_traintest) bind_rows( mutate(predict_accuracy_fulldata, type = &quot;Full Data&quot;), mutate(predict_accuracy_traintest, type = &quot;Train/Test&quot;) ) %&gt;% gf_density(~ mean_same_class, color = ~ type, fill = NA, size = 1.25) 5.1.7 Cross-validation "],
["linear-model.html", "Chapter 6 Linear Model 6.1 Simple Regression continuous predictor 6.2 Conditional Means 6.3 Categorical Predictor(s) 6.4 Multiple Regression", " Chapter 6 Linear Model 6.1 Simple Regression continuous predictor 6.2 Conditional Means 6.3 Categorical Predictor(s) 6.4 Multiple Regression "],
["estimation-bootstrap-uncertainty.html", "Chapter 7 Estimation / Bootstrap / Uncertainty", " Chapter 7 Estimation / Bootstrap / Uncertainty "],
["prediction-for-individuals.html", "Chapter 8 Prediction for individuals 8.1 Comparison of classification / linear model", " Chapter 8 Prediction for individuals 8.1 Comparison of classification / linear model "]
]
